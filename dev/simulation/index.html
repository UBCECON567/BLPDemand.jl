<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Simulations · BLPDemand.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">BLPDemand.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Simulations</a><ul class="internal"><li><a class="tocitem" href="#Generate-Data-1"><span>Generate Data</span></a></li><li><a class="tocitem" href="#Instruments-1"><span>Instruments</span></a></li><li><a class="tocitem" href="#Estimation-1"><span>Estimation</span></a></li><li><a class="tocitem" href="#Inference-1"><span>Inference</span></a></li><li><a class="tocitem" href="#Optimal-Instruments-1"><span>Optimal Instruments</span></a></li><li><a class="tocitem" href="#Calculating-Elasticities-1"><span>Calculating Elasticities</span></a></li></ul></li><li><a class="tocitem" href="../functions/">Function Reference</a></li><li><a class="tocitem" href="../replicateblp/">Replicating BLP</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Simulations</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Simulations</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/UBCECON567/BLPDemand.jl/blob/master/docs/src/simulation.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Simulations-1"><a class="docs-heading-anchor" href="#Simulations-1">Simulations</a><a class="docs-heading-anchor-permalink" href="#Simulations-1" title="Permalink"></a></h1><p>Here we perform some monte-carlo simulations to illustrute package usage and estimator performance. See <a href="@ref"><code>Model</code></a> for an overview of the model. The tests directory contains some additional examples.</p><h2 id="Generate-Data-1"><a class="docs-heading-anchor" href="#Generate-Data-1">Generate Data</a><a class="docs-heading-anchor-permalink" href="#Generate-Data-1" title="Permalink"></a></h2><pre><code class="language-julia">using BLPDemand, Statistics, PrettyTables, Printf, Random, LinearAlgebra
K = 3             # number of characteristics
J = 5             # number of products
S = 10            # draws of nu
T = 100           # number of markets
β = ones(K)*2
β[1] = -1.5       # important for equilibrium that higher prices lower sales
σ = ones(K)
σ[1] = 0.2
γ = ones(2)*0.3
Random.seed!(984256)

(sim, ξ, ω) = simulateBLP(J,T, β, σ, γ, S, varξ=0.2, varω=0.2)
@show quantile(vcat((d-&gt;d.s[:]).(sim)...), [0, 0.05, 0.5, 0.95, 1])</code></pre><pre><code class="language-none">5-element Array{Float64,1}:
 0.009680471739927464
 0.01860600555710775 
 0.1020752923857159  
 0.2738458306933879  
 0.4011829910117323  </code></pre><p>Estimation will encounter numerical difficulties if market shares are very close (within 1e-4) to 0 or 1. The above range should be fine. </p><h2 id="Instruments-1"><a class="docs-heading-anchor" href="#Instruments-1">Instruments</a><a class="docs-heading-anchor-permalink" href="#Instruments-1" title="Permalink"></a></h2><p>In the simulated data <code>sim[].x[2:end,:]</code> and <code>sim[].w</code> are uncorrelated with <code>ξ</code> and <code>ω</code>, but price, <code>sim[].x[1,:]</code>, is endogenous. The price of the <code>j</code>th firm will depend on the characteristics and costs of all other goods, so these are available as instruments. <a href="../functions/#BLPDemand.makeivblp-Tuple{AbstractArray{T,2} where T}"><code>makeivblp</code></a> is a convenience function that constructs the sum of all other firms&#39; exogenous variables to use as instruments. This is similar to what Berry, Levinsohn, and Pakes (1995) do. We will see below though that much more accurate estimates can be obtained by using the optimal instruments. <code>makeivblp</code> is used by <code>simulateBLP</code> to generate <code>sim[].zd</code> and <code>sim[].zs</code>.</p><h2 id="Estimation-1"><a class="docs-heading-anchor" href="#Estimation-1">Estimation</a><a class="docs-heading-anchor-permalink" href="#Estimation-1" title="Permalink"></a></h2><p>We can now estimate the model. Three methods are available: GMM with nested-fixed point (<code>:NFXP</code>), constrained GMM (<code>:MPEC</code>), and constrained GEL (<code>:GEL</code>). See <a href="../functions/#BLPDemand.estimateBLP-Tuple{Array{MarketData,1}}"><code>estimateBLP</code></a>. </p><pre><code class="language-julia-repl">julia&gt; @time nfxp = estimateBLP(sim, method=:NFXP, verbose=false)
(β0, σ0, γ0) = ([-1.6217851933020269, 1.9198292402880808, 1.9893279216106112], [1.0, 1.0, 1.0], [0.35386147899085313, 0.2672723450624416])
objectiveBLP(θ0) = 269927.0168125381
 70.588879 seconds (268.64 M allocations: 15.335 GiB, 8.88% gc time)
(β = [-1.4231296989453783, 1.9523999408209258, 2.0561506852481126], σ = [0.35741767527346374, 0.9710744104740744, 0.9273803359118651], γ = [0.31554067603859903, 0.25289434136511985], ξ = Array{Float64,1}[[0.08029507314179815, 0.07973151651843391, -0.08425420642017012, 0.4114391093876539, 0.11746368981203426], [-0.33402599906798947, 0.09980087835324888, 0.2620285764584671, -0.09757154508894383, 0.1590848335072779], [-0.1984810381676409, 0.020460544400782432, -0.06830305018115568, 0.15944928201731257, 0.019044642512873883], [-0.3447202990927456, 0.08349114060647123, 0.22666897341015696, -0.30370086114864625, -0.37123509777723385], [-0.15477801975146188, -0.30266191336146253, -0.01856015003395453, -0.26295409998919717, 0.01746894615154404], [0.17189286011369798, 0.1405199193490378, -0.18976001251098834, 0.2370034020780709, 0.1607204838504671], [0.29529235234939943, -0.22855159593963625, 0.034229859010013935, -0.07184108301702641, -0.2910753653069804], [0.11862282653072127, 0.09997296463750471, 0.04223202747484181, -0.38698290522738743, -0.03438862686079358], [-0.18836362510555893, -0.222386211235317, 0.12413684825467142, -0.012523380331862954, 0.11524444835357639], [0.11785902703410844, -0.18784257112874192, 0.038809187256916455, 0.06899725950033875, -0.21939157265711473]  …  [-0.2105426292348156, -0.17647523172212365, 0.12371844005292804, 0.08309303854284564, 0.12062274551818747], [-0.16787132173619979, 0.20912626156292446, -0.6209834757701616, 0.4632105839377214, 0.06056303542609698], [0.26399903096500754, 0.40067281408347055, -0.336684465651218, -0.03998379750057279, -0.18596509400080263], [-0.15362940678097226, -0.1944633493451724, -0.019662904451177354, -0.39416366640836464, -0.16981266471521117], [-0.051293724445439004, 0.06615449342837376, -0.1763707697513094, -0.10198897177829791, 0.07274778704362084], [0.37628471778499417, 0.08419090265931395, -0.04152688080174016, 0.16526374339731553, -0.1076974008774434], [-0.18181695648444002, 0.2878718533940659, -0.2292810223250079, -0.1396472861963859, 0.1693636314535948], [0.0004391456186130238, -0.1562194722477992, 0.19870180145703875, 0.09947527813346452, -0.15708945089789483], [0.15506348607692233, 0.031782043161069584, 0.057629047081840135, 0.0574467157919126, -0.32011169712982834], [-0.18753207301080588, -0.018759536826280288, 0.056005107756052996, -0.2734057236498483, -0.13816342363223577]], ω = Array{Float64,1}[[-0.09602934527749457, -0.2964734347131762, 0.41284571326541314, -0.21477082840192868, 0.015236285220474682], [-0.2921427001954098, -0.19725561181557574, -0.06169033676066524, 0.3471241881720808, -0.03128555750805498], [-0.10372656207291425, -0.18295320491853712, 0.291649429284473, 0.20648428533120944, -0.23962353947430262], [0.0393741825606759, -0.04066752336557508, 0.16759041286986143, -0.05626242280678234, -0.11321000073507098], [0.3638692684288076, -0.38261935440335393, -0.01344157441582837, -0.17733644095868129, 0.39199897579456877], [0.03657851144831922, -0.014464600345133305, -0.25900742374169256, 0.36873520275414423, -0.06865928347329558], [0.2353341472776897, 0.09195245310495959, -0.28969981766528197, -0.05728430822796654, 0.0809296356244456], [-0.5147356991026586, 0.054725352855979736, -0.09116234156082054, 0.22887373709582517, -0.13072438569385586], [0.15279020517578268, 0.06417193862288562, 0.04772434996547997, 0.020760393882845785, 0.28733429183870407], [-0.10845841357291364, 0.04512268903282496, -0.056403095148267024, -0.0566111399839333, -0.17209542711732742]  …  [0.23677940066913583, 0.26558890879208896, -0.16900305716352082, -0.02781244643617281, 0.25349315240558146], [0.355168668996534, 0.09809097486658183, -0.41594164394194016, 0.032680180868952274, 0.12208029121241692], [0.029320601858646322, -0.056318468449974624, 0.09458637104383233, 0.16212808208552, -0.11044647874720954], [-0.009441254654875691, 0.05921011096709172, 0.40999257072588546, 0.001263953933491796, 0.32076152861019547], [0.08557325409506572, 0.05449231034436641, -0.10702581420560413, 0.19080698586025124, 0.3265603485427011], [0.16956327788142078, -0.017874003027677915, 0.0640104986279798, -0.029830956803441777, -0.1787992145443701], [0.04220600838906771, 0.07563127677752104, 0.24996739325913075, -0.35358779950000013, -0.19881046631258809], [0.2690961912849818, -0.12125214046139454, 0.17083291854898536, -0.03214825820976197, -0.3665587435184442], [0.023544537533041865, 0.12595703325252366, -0.05404599142310784, 0.08499994210391312, 0.05852784177481013], [0.09386353299111116, 0.01528892846422747, 0.0926931803971041, 0.11464673869731073, -0.3086047700611628]], opt =  * Status: failure (objective increased between iterations) (line search failed)

 * Candidate solution
    Minimizer: [-1.42e+00, 1.95e+00, 2.06e+00,  ...]
    Minimum:   1.523240e-01

 * Found with
    Algorithm:     L-BFGS
    Initial Point: [-1.62e+00, 1.92e+00, 1.99e+00,  ...]

 * Convergence measures
    |x - x&#39;|               = 3.21e-04 ≰ 0.0e+00
    |x - x&#39;|/|x&#39;|          = 1.56e-04 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 1.60e-09 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 1.05e-08 ≰ 0.0e+00
    |g(x)|                 = 1.69e-02 ≰ 1.0e-08

 * Work counters
    Seconds run:   14  (vs limit Inf)
    Iterations:    300
    f(x) calls:    815
    ∇f(x) calls:   815
)

julia&gt; @time mpec = estimateBLP(sim, method=:MPEC,verbose=true);
(β0, σ0, γ0) = ([-1.6217851933020269, 1.9198292402880808, 1.9893279216106112], [1.0, 1.0, 1.0], [0.35386147899085313, 0.2672723450624416])

******************************************************************************
This program contains Ipopt, a library for large-scale nonlinear optimization.
 Ipopt is released as open source code under the Eclipse Public License (EPL).
         For more information visit http://projects.coin-or.org/Ipopt
******************************************************************************

This is Ipopt version 3.12.10, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

Number of nonzeros in equality constraint Jacobian...:    12500
Number of nonzeros in inequality constraint Jacobian.:        0
Number of nonzeros in Lagrangian Hessian.............:   586000

Total number of variables............................:     1008
                     variables with only lower bounds:        3
                variables with lower and upper bounds:        0
                     variables with only upper bounds:        0
Total number of equality constraints.................:     1000
Total number of inequality constraints...............:        0
        inequality constraints with only lower bounds:        0
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        0

iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  2.2705090e+05 1.57e+00 1.00e+02  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0
   1  5.2798565e-01 1.88e+00 9.58e-02  -1.0 1.78e+00    -  1.00e+00 1.00e+00f  1
   2  3.8941108e-01 3.58e-01 2.17e-02  -1.0 3.24e-01    -  1.00e+00 1.00e+00h  1
   3  2.3086617e-01 1.91e-02 9.99e-03  -1.7 1.84e-01    -  1.00e+00 1.00e+00h  1
   4  1.7088023e-01 3.57e-03 4.44e-03  -2.5 2.07e-01    -  1.00e+00 1.00e+00h  1
   5  1.5475399e-01 1.54e-03 6.87e-04  -3.8 1.36e-01    -  1.00e+00 1.00e+00h  1
   6  1.5246409e-01 1.31e-04 3.96e-05  -3.8 3.93e-02    -  1.00e+00 1.00e+00h  1
   7  1.5232406e-01 4.78e-06 1.89e-06  -5.7 7.44e-03    -  1.00e+00 1.00e+00h  1
   8  1.5231966e-01 4.02e-09 1.42e-09  -8.6 2.17e-04    -  1.00e+00 1.00e+00h  1

Number of Iterations....: 8

                                   (scaled)                 (unscaled)
Objective...............:   1.7528867766346403e-02    1.5231965986825696e-01
Dual infeasibility......:   1.4187162564665646e-09    1.2328142382900523e-08
Constraint violation....:   4.0176527660307215e-09    4.0176527660307215e-09
Complementarity.........:   7.0553801207703916e-09    6.1308757334587691e-08
Overall NLP error.......:   7.0553801207703916e-09    6.1308757334587691e-08


Number of objective function evaluations             = 9
Number of objective gradient evaluations             = 9
Number of equality constraint evaluations            = 9
Number of inequality constraint evaluations          = 0
Number of equality constraint Jacobian evaluations   = 9
Number of inequality constraint Jacobian evaluations = 0
Number of Lagrangian Hessian evaluations             = 8
Total CPU secs in IPOPT (w/o function evaluations)   =     18.120
Total CPU secs in NLP function evaluations           =      3.205

EXIT: Optimal Solution Found.
 52.455719 seconds (67.93 M allocations: 3.494 GiB, 4.32% gc time)

julia&gt; @time gel = estimateBLP(sim, method=:GEL,verbose=true);
(β0, σ0, γ0) = ([-1.6217851933020269, 1.9198292402880808, 1.9893279216106112], [1.0, 1.0, 1.0], [0.35386147899085313, 0.2672723450624416])
This is Ipopt version 3.12.10, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

Number of nonzeros in equality constraint Jacobian...:    36500
Number of nonzeros in inequality constraint Jacobian.:     1000
Number of nonzeros in Lagrangian Hessian.............:    98000

Total number of variables............................:     1508
                     variables with only lower bounds:        3
                variables with lower and upper bounds:        0
                     variables with only upper bounds:        0
Total number of equality constraints.................:     1012
Total number of inequality constraints...............:      501
        inequality constraints with only lower bounds:      500
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        1

iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  3.1073040e+03 4.09e+00 9.33e+01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0
   1  3.1024637e+03 4.01e+00 2.63e+01  -1.0 2.67e+00    -  1.00e+00 1.72e-02h  1
   2  3.1083569e+03 1.69e+00 2.37e+01  -1.0 1.78e+00    -  1.00e+00 1.00e+00h  1
   3  3.1083588e+03 2.79e-01 4.51e+01  -1.0 4.77e-01    -  1.00e+00 1.00e+00h  1
   4  3.1085832e+03 1.43e-02 4.41e+00  -1.0 8.02e-02    -  1.00e+00 1.00e+00h  1
   5  3.1085644e+03 3.23e-05 4.69e-02  -1.0 1.50e-02    -  1.00e+00 1.00e+00h  1
   6  3.1083300e+03 1.68e-04 1.64e+00  -2.5 4.95e-02    -  9.79e-01 1.00e+00h  1
   7  3.1082201e+03 8.73e-05 7.31e-02  -2.5 3.64e-02    -  1.00e+00 1.00e+00h  1
   8  3.1082169e+03 1.54e-07 3.29e-04  -2.5 1.52e-03    -  1.00e+00 1.00e+00h  1
   9  3.1082038e+03 1.25e-06 1.98e-03  -3.8 4.39e-03    -  1.00e+00 1.00e+00h  1
iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
  10  3.1082036e+03 7.61e-10 7.50e-07  -3.8 1.09e-04    -  1.00e+00 1.00e+00h  1
  11  3.1082029e+03 4.24e-09 6.45e-06  -5.7 2.55e-04    -  1.00e+00 1.00e+00h  1
  12  3.1082028e+03 8.08e-13 1.13e-09  -8.6 3.53e-06    -  1.00e+00 1.00e+00h  1

Number of Iterations....: 12

                                   (scaled)                 (unscaled)
Objective...............:   6.2164056858241111e+02    3.1082028429120555e+03
Dual infeasibility......:   1.1257270671194419e-09    5.6286353355972096e-09
Constraint violation....:   8.0811746183684363e-13    8.0811746183684363e-13
Complementarity.........:   2.5239366217092741e-09    1.2619683108546370e-08
Overall NLP error.......:   2.5239366217092741e-09    1.2619683108546370e-08


Number of objective function evaluations             = 13
Number of objective gradient evaluations             = 13
Number of equality constraint evaluations            = 13
Number of inequality constraint evaluations          = 13
Number of equality constraint Jacobian evaluations   = 13
Number of inequality constraint Jacobian evaluations = 13
Number of Lagrangian Hessian evaluations             = 12
Total CPU secs in IPOPT (w/o function evaluations)   =      0.276
Total CPU secs in NLP function evaluations           =      2.309

EXIT: Optimal Solution Found.
  7.131005 seconds (9.92 M allocations: 747.645 MiB, 8.60% gc time)</code></pre><pre><code class="language-julia">tbl = vcat([&quot;&quot; &quot;True&quot; &quot;NFXP&quot; &quot;MPEC&quot; &quot;GEL&quot;],
           [(i-&gt;&quot;β[$i]&quot;).(1:length(β)) β nfxp.β mpec.β gel.β],
           [(i-&gt;&quot;σ[$i]&quot;).(1:length(σ)) σ nfxp.σ mpec.σ gel.σ],
           [(i-&gt;&quot;γ[$i]&quot;).(1:length(γ)) γ nfxp.γ mpec.γ gel.γ])
pretty_table(tbl, noheader=true, formatter=ft_printf(&quot;%6.3f&quot;,3:5))</code></pre><pre><code class="language-none">┌──────┬──────┬────────┬────────┬────────┐
│      │ True │   NFXP │   MPEC │    GEL │
│ β[1] │ -1.5 │ -1.423 │ -1.423 │ -1.372 │
│ β[2] │  2.0 │  1.952 │  1.953 │  1.958 │
│ β[3] │  2.0 │  2.056 │  2.056 │  2.064 │
│ σ[1] │  0.2 │  0.357 │  0.357 │  0.465 │
│ σ[2] │  1.0 │  0.971 │  0.971 │  0.936 │
│ σ[3] │  1.0 │  0.927 │  0.928 │  0.907 │
│ γ[1] │  0.3 │  0.316 │  0.316 │  0.297 │
│ γ[2] │  0.3 │  0.253 │  0.253 │  0.269 │
└──────┴──────┴────────┴────────┴────────┘</code></pre><p>In the absence of optimization error and other numeric problems, <code>:NFXP</code> and <code>:MPEC</code> should produce identical results.  In finite sample, we should expect the GEL estimates to differ. All three methods are consistent, but GEL is also asymptotically efficient (for a fixed choice of <code>z</code>; different <code>z</code> can have large effects on efficiency).</p><h2 id="Inference-1"><a class="docs-heading-anchor" href="#Inference-1">Inference</a><a class="docs-heading-anchor-permalink" href="#Inference-1" title="Permalink"></a></h2><p><a href="../functions/#BLPDemand.varianceBLP-Tuple{Any,Any,Any,Array{MarketData,1}}"><code>varianceBLP</code></a> computes the variance of the estimates produced by either of GMM estimation methods.<sup class="footnote-reference"><a id="citeref-simdraws" href="#footnote-simdraws">[simdraws]</a></sup></p><p>[^simdraws:] The variance calculation ignores uncertainty from Monte-Carlo integration. For this to be valid, we must have the number of simulation draws grow faster than the sample size. In our notation, <code>S</code> is the number of simulation draws per observation, so it is sufficient at that <span>$S \to \infty$</span> as <span>$T \to \infty$</span>.</p><pre><code class="language-julia">vnfxp = varianceBLP(nfxp.β, nfxp.σ, nfxp.γ, sim);
vmpec = varianceBLP(mpec.β, mpec.σ, mpec.γ, sim);
nothing</code></pre><p>Inference for GEL has not been directly implemented. However, GEL is first order asymptotically equivalent to efficiently weigthed GMM. In other words, GEL estimates have the same asymptotic variance as efficiently weighted GMM. </p><pre><code class="language-julia">v = varianceBLP(gel.β, gel.σ, gel.γ, sim)
vgel = varianceBLP(gel.β, gel.σ, gel.γ, sim, W=inv(v.varm))

f(v) = @sprintf(&quot;(%.2f)&quot;, norm(sqrt(Complex(v))))
vtbl = permutedims(hcat(tbl[1,:],
                        [hcat(tbl[i+1,:],
                              [&quot;&quot;, &quot;&quot;, f.([vnfxp.Σ[i,i], vmpec.Σ[i,i], vgel.Σ[i,i]])...])
                         for i in 1:size(vgel.Σ,1)]...
                        ))
pretty_table(vtbl, noheader=true, formatter=ft_printf(&quot;%6.3f&quot;,3:5))</code></pre><pre><code class="language-none">┌──────┬──────┬────────┬────────┬────────┐
│      │ True │   NFXP │   MPEC │    GEL │
│ β[1] │ -1.5 │ -1.423 │ -1.423 │ -1.372 │
│      │      │ (0.20) │ (0.20) │ (0.20) │
│ β[2] │  2.0 │  1.952 │  1.953 │  1.958 │
│      │      │ (0.05) │ (0.05) │ (0.05) │
│ β[3] │  2.0 │  2.056 │  2.056 │  2.064 │
│      │      │ (0.05) │ (0.05) │ (0.05) │
│ σ[1] │  0.2 │  0.357 │  0.357 │  0.465 │
│      │      │ (0.39) │ (0.39) │ (0.39) │
│ σ[2] │  1.0 │  0.971 │  0.971 │  0.936 │
│      │      │ (0.13) │ (0.13) │ (0.12) │
│ σ[3] │  1.0 │  0.927 │  0.928 │  0.907 │
│      │      │ (0.12) │ (0.12) │ (0.13) │
│ γ[1] │  0.3 │  0.316 │  0.316 │  0.297 │
│      │      │ (0.06) │ (0.06) │ (0.05) │
│ γ[2] │  0.3 │  0.253 │  0.253 │  0.269 │
│      │      │ (0.04) │ (0.04) │ (0.04) │
└──────┴──────┴────────┴────────┴────────┘</code></pre><p>These reusults look pretty good. In additional experiments (not shown)  the results were somewhat sensitive to the simulation design and choice of instruments (see <a href="../functions/#BLPDemand.makeivblp-Tuple{AbstractArray{T,2} where T}"><code>makeivblp</code></a>).</p><h2 id="Optimal-Instruments-1"><a class="docs-heading-anchor" href="#Optimal-Instruments-1">Optimal Instruments</a><a class="docs-heading-anchor-permalink" href="#Optimal-Instruments-1" title="Permalink"></a></h2><p>The above estimators use the unconditional moment restriction </p><div>\[E[(\xi, \omega) z] =0.\]</div><p>If we assume the conditional moment restriction,</p><div>\[E[(\xi, \omega) | z] =0.\]</div><p>then, we can potentially use any function of <span>$z$</span> to form unconditional moments. </p><div>\[E[(\xi, \omega) f(z)] =0.\]</div><p>The optimal (minimal asymptotic variance) choice of <code>f(z)</code> is </p><div>\[\frac{\partial}{\partial \theta} E[(\xi, \omega) | z] =0.\]</div><p><a href="../functions/#BLPDemand.optimalIV-Tuple{Any,Any,Any,Array{MarketData,1}}"><code>optimalIV</code></a> approximates the optimal instruments by taking as initial estimate of <span>$\theta$</span>, computing <span>$\frac{\partial (\xi, \omega)}{\partial \theta}$</span> for each observation in the data, and then regressing this on a polynomial function of <span>$z$</span>. Using the fitted values from this regression as <span>$f(z)$</span> results in much more precise estimates of <span>$\theta$</span>.<sup class="footnote-reference"><a id="citeref-z" href="#footnote-z">[z]</a></sup></p><pre><code class="language-julia">sim=optimalIV(mpec.β, max.(mpec.σ, 0.1), # calculating optimal IV with σ near 0 gives poor peformance
              mpec.γ, sim, degree=3);
nothing</code></pre><pre><code class="language-julia-repl">julia&gt; @time nfxp = estimateBLP(sim, method=:NFXP, verbose=false)
(β0, σ0, γ0) = ([-1.618257198686724, 1.9136315124045826, 1.982925142070414], [1.0, 1.0, 1.0], [0.3529797661774927, 0.2662760924645476])
objectiveBLP(θ0) = 1.0814359300882824e7
 16.810653 seconds (131.07 M allocations: 7.725 GiB, 19.31% gc time)
(β = [-1.463772880349104, 1.890099975074887, 1.9905774370382283], σ = [0.2799395907022754, 2.6959724479475132e-8, 0.5592832292568235], γ = [0.3474417163429128, 0.25786629073659967], ξ = Array{Float64,1}[[-0.008079628865248711, -0.0896800726789525, 0.08019365165248837, 0.26771956479246095, 0.13728261125416208], [-0.0998413505591963, -0.020835926473779354, 0.5447428141668376, -0.012831919970713201, 0.4790835294442902], [-0.3157593259894031, -0.09628432023753947, -0.19033790336528122, 0.025146933613183986, -0.08616449025061251], [-0.5469295113009823, -0.07752288174035377, 0.0547208476510439, -0.4819920890510639, -0.3927624095300999], [-0.021124445493429178, -0.2936635624858246, 0.10603148029451587, -0.04173116520650538, 0.23682517239634682], [0.32703330744359393, 0.3444274482368094, 0.0809265123564602, 0.3358764595445072, 0.36272131585119627], [0.20522087330761263, -0.35632353952491824, 0.0024166498080500825, -0.20139248146730915, -0.3568027372500304], [-0.03108683345831037, 0.013763955348657486, -0.06019575112197165, -0.4825399458028281, -0.13613376385748865], [-0.10251198160866304, -0.1516940983982744, 0.3364401638116892, 0.1396642573335043, 0.24143271500920882], [0.4391208360006047, 0.033356486615171654, 0.2862279000405986, 0.13013830777641333, -0.12420487701761651]  …  [-0.6674532817316567, -0.5139963079156575, -0.1423079641120919, -0.12937266271338227, -0.09581643766155457], [-0.7303374377197178, -0.315020499124417, -0.6480120878024334, -0.08054222684978396, -0.27283632047875184], [0.30075302004491333, 0.4436803340415043, -0.17409015535177963, 0.24505876311005392, -0.08281961359610501], [-0.02403993513199998, -0.10796047258934238, 0.23633953538644992, -0.1088222467778992, -0.026506080417927347], [-0.10502241272052647, -0.06819124567830218, -0.36128543909765076, -0.07868022320049184, 0.16237979973122865], [0.29575649437657603, -0.016483021930437047, -0.04742391915616695, 0.0934520144420461, -0.2201714375520154], [-0.5885616953777624, -0.08008262372214903, -0.56744185700156, -0.5580881897170252, -0.07511735343068149], [-0.06811044019407486, -0.05218286736743605, 0.1770388061917565, 0.10167759886179184, -0.1674379537884625], [0.023120956694088313, -0.11042027969805313, 0.0408532364354901, -0.007512254959503917, -0.14567140425774228], [-0.21466131868056149, -0.016141952107984414, 0.13849770682087714, -0.07976258595092567, -0.18019740826438735]], ω = Array{Float64,1}[[-0.11727616242991257, -0.2891917948440972, 0.3951691845502471, -0.2214377557524976, 0.0013980863108061237], [-0.3017429254049946, -0.17980890048205547, -0.05350562271148809, 0.3361133873193847, 0.036001729908375774], [-0.11684490807000537, -0.19409292443669204, 0.2677027927759227, 0.18076913565625224, -0.25245731015650463], [0.03927937150562649, -0.03593248995922449, 0.1554555071843649, -0.07066868472999283, -0.12813873120274338], [0.35320940474688683, -0.3986776257697791, -0.016351384014988396, -0.1914396421840504, 0.38541269124706434], [0.03434940672941211, -0.017884040978100008, -0.2331830474470751, 0.36919203655191435, -0.09564293675088648], [0.23968213408459246, 0.08886602050598615, -0.2620148971940496, -0.09129724520252808, 0.049596496469888396], [-0.49910916049132353, 0.040034258784008236, -0.04722949248413014, 0.21746115067186633, -0.14333423638673892], [0.13015504092434563, 0.04494914510435222, 0.06368983256158667, 0.010652387993575152, 0.2701301475876664], [-0.13294357445095775, 0.020070661214158236, -0.08853587589412476, -0.08532395972797219, -0.18866900483035012]  …  [0.2044389318483908, 0.23849154891468455, -0.15707804017612095, -0.025974760065880398, 0.26601135221862365], [0.3289009071579393, 0.1139797814606236, -0.4045063768065987, 0.049332112482707885, 0.09335413393155201], [0.02344615785191906, -0.06472377426219152, 0.08755466819967667, 0.14942789040115328, -0.12140688347200997], [-0.02063470322084654, 0.03969861285626092, 0.38790219299373996, 0.040121744019872424, 0.2957971697855988], [0.08668302060370114, 0.0447970303597415, -0.10956133032506668, 0.1781714799308871, 0.3625004544851052], [0.13687180627319173, -0.04020822496807916, 0.06849986761878579, -0.0474303549240323, -0.20415964853988416], [0.021814337250079474, 0.08109380834429583, 0.22743954686938683, -0.27979950685639, -0.20987328543958444], [0.25703174193765377, -0.14092508525379438, 0.1504036665021698, -0.025573597222339206, -0.3928508092239371], [0.010216513946190886, 0.09863250321702577, -0.06461636905728282, 0.13956334586565797, 0.047596540465255965], [0.06539342896330458, -0.014414858238675055, 0.1330714010418213, 0.12253884166974977, -0.3187143730607678]], opt =  * Status: failure (objective increased between iterations) (line search failed)

 * Candidate solution
    Minimizer: [-1.46e+00, 1.89e+00, 1.99e+00,  ...]
    Minimum:   1.057059e+00

 * Found with
    Algorithm:     L-BFGS
    Initial Point: [-1.62e+00, 1.91e+00, 1.98e+00,  ...]

 * Convergence measures
    |x - x&#39;|               = 8.83e-04 ≰ 0.0e+00
    |x - x&#39;|/|x&#39;|          = 5.07e-05 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 4.18e-08 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 3.96e-08 ≰ 0.0e+00
    |g(x)|                 = 4.63e-01 ≰ 1.0e-08

 * Work counters
    Seconds run:   17  (vs limit Inf)
    Iterations:    347
    f(x) calls:    931
    ∇f(x) calls:   931
)

julia&gt; @time mpec = estimateBLP(sim, method=:MPEC,verbose=false);
(β0, σ0, γ0) = ([-1.618257198686724, 1.9136315124045826, 1.982925142070414], [1.0, 1.0, 1.0], [0.3529797661774927, 0.2662760924645476])
 43.567431 seconds (14.73 M allocations: 944.641 MiB, 1.37% gc time)

julia&gt; @time gel = estimateBLP(sim, method=:GEL,verbose=false);
(β0, σ0, γ0) = ([-1.618257198686724, 1.9136315124045826, 1.982925142070414], [1.0, 1.0, 1.0], [0.3529797661774927, 0.2662760924645476])
  4.138643 seconds (3.03 M allocations: 391.394 MiB, 7.02% gc time)</code></pre><pre><code class="language-julia">vnfxp = varianceBLP(nfxp.β, nfxp.σ, nfxp.γ, sim)
vmpec = varianceBLP(mpec.β, mpec.σ, mpec.γ, sim)
v = varianceBLP(gel.β, gel.σ, gel.γ, sim)
vgel = varianceBLP(gel.β, gel.σ, gel.γ, sim, W=inv(v.varm))

f(v) = @sprintf(&quot;(%.2f)&quot;, norm(sqrt(Complex(v))))
tbl = vcat([&quot;&quot; &quot;True&quot; &quot;NFXP&quot; &quot;MPEC&quot; &quot;GEL&quot;],
           [(i-&gt;&quot;β[$i]&quot;).(1:length(β)) β nfxp.β mpec.β gel.β],
           [(i-&gt;&quot;σ[$i]&quot;).(1:length(σ)) σ nfxp.σ mpec.σ gel.σ],
           [(i-&gt;&quot;γ[$i]&quot;).(1:length(γ)) γ nfxp.γ mpec.γ gel.γ])
vtbl = permutedims(hcat(tbl[1,:],
                        [hcat(tbl[i+1,:],
                              [&quot;&quot;, &quot;&quot;, f.([vnfxp.Σ[i,i], vmpec.Σ[i,i], vgel.Σ[i,i]])...])
                         for i in 1:size(vgel.Σ,1)]...
                        ))
pretty_table(vtbl, noheader=true, formatter=ft_printf(&quot;%6.3f&quot;,3:5))</code></pre><pre><code class="language-none">┌──────┬──────┬────────┬────────┬────────┐
│      │ True │   NFXP │   MPEC │    GEL │
│ β[1] │ -1.5 │ -1.464 │ -1.464 │ -1.462 │
│      │      │ (0.06) │ (0.06) │ (0.07) │
│ β[2] │  2.0 │  1.890 │  1.890 │  1.914 │
│      │      │ (0.06) │ (0.06) │ (0.06) │
│ β[3] │  2.0 │  1.991 │  1.991 │  1.988 │
│      │      │ (0.05) │ (0.05) │ (0.07) │
│ σ[1] │  0.2 │  0.280 │  0.280 │  0.307 │
│      │      │ (0.14) │ (0.14) │ (0.13) │
│ σ[2] │  1.0 │  0.000 │  0.000 │  0.000 │
│      │      │ (0.00) │ (0.00) │ (0.00) │
│ σ[3] │  1.0 │  0.559 │  0.559 │  0.005 │
│      │      │ (1.54) │ (1.54) │ (1.35) │
│ γ[1] │  0.3 │  0.347 │  0.347 │  0.346 │
│      │      │ (0.02) │ (0.02) │ (0.02) │
│ γ[2] │  0.3 │  0.258 │  0.258 │  0.264 │
│      │      │ (0.03) │ (0.03) │ (0.02) │
└──────┴──────┴────────┴────────┴────────┘</code></pre><p>We see that with the optimal instruments all three methods produce essentially the same results (in this case, theoretically, NFXP=MPEC, and both are asymptotically equivalent to GEL, so this is expected). Moreover, the estimates are now much more precise and quite close to the true parameter values.</p><h2 id="Calculating-Elasticities-1"><a class="docs-heading-anchor" href="#Calculating-Elasticities-1">Calculating Elasticities</a><a class="docs-heading-anchor-permalink" href="#Calculating-Elasticities-1" title="Permalink"></a></h2><p>Using <a href="../functions/#BLPDemand.share-Tuple{AbstractArray{T,1} where T,AbstractArray{T,1} where T,AbstractArray{T,2} where T,AbstractArray{T,2} where T}"><code>share</code></a> and the <code>ForwardDiff.jl</code> package, we can calculate elasticities of demand with respect to each characteristic.</p><pre><code class="language-julia">using ForwardDiff

function elasticity(β, σ, γ, dat, ξ)
  T = length(dat)
  K,J = size(dat[1].x)
  etype = typeof(dat[1].x[:,1]&#39;*β+ξ[1][1])
  e = Array{Array{etype,3},1}(undef, T)
  for t in 1:T
    @views xt = dat[t].x
    st(x) = share(x&#39;*β + ξ[t], σ, x, dat[t].ν)
    ∂s = reshape(ForwardDiff.jacobian(st, xt), J, K, J)
    s = st(xt)
    e[t] = zeros(etype, J,K,J)
    for k in 1:K
      for j in 1:J
        e[t][:,k,j] .= ∂s[:,k,j]./s .* xt[k,j]
      end
    end
  end
  return e
end

function avg_price_elasticity(β,σ,γ, dat)
  ξ = Vector{Vector{eltype(β)}}(undef, T)
  for t in 1:T
    ξ[t] = delta(dat[t].s, dat[t].x, dat[t].ν, σ) - dat[t].x&#39;*β
  end
  e=elasticity(β,σ,γ,dat,ξ)
  avge = zeros(eltype(e[1]),size(e[1]))
  # this assumes J is the same for all markets
  for t in 1:T
    avge .+= e[t]
  end
  avge /= T
  avge[:,1,:]
end

price_elasticity = avg_price_elasticity(mpec.β, mpec.σ, mpec.γ, sim)</code></pre><pre><code class="language-none">5×5 Array{Float64,2}:
 -3.00316    0.376012   0.417859   0.419862   0.429588
  0.388066  -2.98284    0.418429   0.421729   0.433743
  0.388917   0.375468  -2.97933    0.421742   0.432711
  0.385484   0.375957   0.418374  -2.9656     0.432321
  0.38671    0.377306   0.418883   0.423874  -2.95016 </code></pre><p>Standard errors of elasticities and other quantities calculated from estimates can be calculated using the delta method.</p><pre><code class="language-julia">D = ForwardDiff.jacobian(θ-&gt;avg_price_elasticity(θ[1:K], θ[(K+1):(2K)], θ[(2K+1):end], sim), [mpec.β;mpec.σ;mpec.γ])
V = D*vmpec.Σ*D&#39;
se = reshape(sqrt.(diag(V)), size(price_elasticity))

tbl = Array{Any, 2}(undef, 2J+1, J+1)
tbl[1,1]=&quot;&quot;
for j in 1:J
  tbl[1,j+1] = &quot;price $j&quot;
  tbl[2j,1] = &quot;share $j&quot;
  tbl[2j+1,1] = &quot;&quot;
  for l in 1:J
    tbl[2j, l+1] = price_elasticity[j,l]
    tbl[2j+1, l+1] = @sprintf(&quot;(%.3f)&quot;,se[j,l])
  end
end
pretty_table(tbl, noheader=true, formatter=ft_printf(&quot;%6.3f&quot;, 2:(J+1)))</code></pre><pre><code class="language-none">┌─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐
│         │ price 1 │ price 2 │ price 3 │ price 4 │ price 5 │
│ share 1 │  -3.003 │   0.376 │   0.418 │   0.420 │   0.430 │
│         │ (0.081) │ (0.008) │ (0.004) │ (0.008) │ (0.011) │
│ share 2 │   0.388 │  -2.983 │   0.418 │   0.422 │   0.434 │
│         │ (0.009) │ (0.087) │ (0.005) │ (0.006) │ (0.013) │
│ share 3 │   0.389 │   0.375 │  -2.979 │   0.422 │   0.433 │
│         │ (0.013) │ (0.006) │ (0.096) │ (0.005) │ (0.007) │
│ share 4 │   0.385 │   0.376 │   0.418 │  -2.966 │   0.432 │
│         │ (0.006) │ (0.009) │ (0.005) │ (0.106) │ (0.006) │
│ share 5 │   0.387 │   0.377 │   0.419 │   0.424 │  -2.950 │
│         │ (0.004) │ (0.016) │ (0.007) │ (0.016) │ (0.098) │
└─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘</code></pre><p>The table above shows the estimated average elasticity of each good&#39;s share with respect to each good&#39;s price. Standard errors are in parentheses.</p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-z"><a class="tag is-link" href="#citeref-z">z</a>The choice of <code>z</code> still matters when using <code>optimalIV.</code> For firm <code>j</code>, the values of <code>x[2:end,l,t]</code> (for both <code>l=j</code> and <code>l != j</code>) are all potential instruments for <code>x[1,j,t]</code>. However, <code>makeivblp</code> does not use all of these. It instead uses their sum and the sum of <code>exp(-(x[2:end,j,t] - x[2:end,l,t])^2)</code>. Adjusting these choices might give better results.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../functions/">Function Reference »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 11 February 2020 21:01">Tuesday 11 February 2020</span>. Using Julia version 1.3.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
